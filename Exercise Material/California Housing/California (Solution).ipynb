{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Housing Prices Data Set\n",
    "\n",
    "Create a regression model to predict house prices. See https://www.kaggle.com/camnugent/california-housing-prices for data understanding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local: Fetch the file\n",
    "original_data = pd.read_csv('housing.csv') # Local, use full path if notebook and file in different folders! \n",
    "\n",
    "# Cloud: Fetch the file\n",
    "#my_file = project.get_file(\"housing.csv\")\n",
    "\n",
    "# Read the CSV data file from the object storage into a pandas DataFrame\n",
    "#my_file.seek(0)\n",
    "#original_data = pd.read_csv(my_file)\n",
    "\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.describe(include='all') # descriptive statistics for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.isnull().sum() # check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data[original_data.duplicated(keep=False)] # check for duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates but missing values for \"total_bedrooms\". Decide what to do with these null values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_wo_null = # your code\n",
    "data_wo_null.isnull().sum() # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung \n",
    "data_wo_null = original_data.dropna(axis=0)\n",
    "data_wo_null.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a correlation map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "f,ax=plt.subplots(figsize = (18,18))\n",
    "sns.heatmap(data_wo_null.corr(),annot= True,linewidths=0.5,fmt = \".1f\",ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Correlation Map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove redundant features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reduced_features = data_wo_null[['<your feature 1>', '<your feature 2>','...']]\n",
    "data_reduced_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "data_reduced_features = data_wo_null[['housing_median_age', 'total_rooms', 'median_income', \n",
    "                                      'median_house_value', 'ocean_proximity']] \n",
    "                                        \n",
    "data_reduced_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers\n",
    "The next step is to detect outliers and handle them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reduced_features.hist(figsize=(25,25), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = # your code\n",
    "\n",
    "data_reduced_features_2 = # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung, total_rooms only, more outliers might be removed! \n",
    "q = data_reduced_features['total_rooms'].quantile(0.99)\n",
    "data_reduced_features_2 = data_reduced_features[data_reduced_features['total_rooms']<q]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for modeling\n",
    "\n",
    "Get dummies since there is a categorical feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = # your code\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "dummies = pd.get_dummies(data_reduced_features_2, drop_first=True)\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set X and y (predictors and target) according to your dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dummies['<your target column>']\n",
    "predictors = # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "target = dummies['median_house_value']\n",
    "predictors = dummies.drop(['median_house_value'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training and test sets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.2, random_state=123) # 80-20 split into training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use StandardScaler to scale your predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = # your code \n",
    "# your code\n",
    "\n",
    "X_train = # your code\n",
    "X_test = # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression model and evaluation\n",
    "\n",
    "Create a linear regression model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training performance')\n",
    "print(reg.score(X_train,y_train))\n",
    "print('test performance')\n",
    "print(reg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "test = pd.DataFrame({'Predicted':y_pred,'Actual':y_test})\n",
    "fig= plt.figure(figsize=(16,8))\n",
    "test = test.reset_index()\n",
    "test = test.drop(['index'],axis=1)\n",
    "plt.plot(test[:50])\n",
    "plt.legend(['Actual','Predicted'])\n",
    "sns.jointplot(x='Actual',y='Predicted',data=test,kind='reg',);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an XGBoost regression model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor()\n",
    "# your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "xgb.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "print('training performance')\n",
    "print(xgb.score(X_train,y_train))\n",
    "print('test performance')\n",
    "print(xgb.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(X_test)\n",
    "test = pd.DataFrame({'Predicted':y_pred,'Actual':y_test})\n",
    "fig= plt.figure(figsize=(16,8))\n",
    "test = test.reset_index()\n",
    "test = test.drop(['index'],axis=1)\n",
    "plt.plot(test[:100])\n",
    "plt.legend(['Actual','Predicted'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the result and feel free to try out further analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Remarks_ \n",
    "\n",
    "- some overfitting for XGBoost\n",
    "- cf. https://www.kaggle.com/ravichaubey1506/end-to-end-machine-learning for a more advanced example of this use case\n",
    "- cf. https://people.duke.edu/~rnau/rsquared.htm if you are interested in learning more about evaluating regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment and model usage\n",
    "\n",
    "Discuss the following questions\n",
    "- How could you deploy the model?\n",
    "- Who could be potential users of the model?\n",
    "- How could the model be integrated into existing IT infrastructures and digital services? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
